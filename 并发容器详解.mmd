Mind Map generated by NB MindMap plugin   
> __version__=`1.1`,showJumps=`true`
---

# 并发容器\(数据结构\)

## BlockingQueue（阻塞队列）
- NOTE
<pre>BlockingQueue是指其中的元素数量存在界限，当队列已满时（队列元素数量达到了最大容量的临界值），
对队列进行写入操作的线程将被阻塞挂起，当队列为空时（队列元素数量达到了为0的临界值），
对队列进行读取的操作线程将被阻塞挂起。实际上，BlockingQueue（LinkedTransferQueue除外）
的内部实现主要依赖于显式锁Lock及其与之关联的Condition。因此涉及的所有BlockingQueue的实现都是线程安全的队列，
在高并发的程序开发中，可以不用担心线程安全的问题而直接使用，另外，BlockingQueue在线程池服务
（ExecutorService）中主要扮演着提供线程对任务存取容器的角色，因此了解每一个BlockingQueue的
使用场景和特点就是本节的主要目的之一。</pre>

### ArrayBlockingQueue
- NOTE
<pre>ArrayBlockingQueue是一个基于数组结构实现的FIFO阻塞队列，在构造该阻塞队列时需要指定队列中
最大元素的数量（容量）。当队列已满时，若再次进行数据写入操作，则线程将会进入阻塞，
一直等待直到其他线程对元素进行消费。当队列为空时，对该队列的消费线程将会进入阻塞，
直到有其他线程写入数据。该阻塞队列中提供了不同形式的读写方法：
1. 阻塞式写方法
在ArrayBlockingQueue中提供了两个阻塞式写方法，分别如下（在该队列中，无论是阻塞式写方法还是非阻塞式写方法，都不允许写入null）。
▪ void put(E e)：向队列的尾部插入新的数据，当队列已满时调用该方法的线程会进入阻塞，
直到有其他线程对该线程执行了中断操作，或者队列中的元素被其他线程消费。
▪ boolean offer(E e, long timeout, TimeUnit unit)：向队列尾部写入新的数据，
当队列已满时执行该方法的线程在指定的时间单位内将进入阻塞，直到到了指定的超时时间后，
或者在此期间有其他线程对队列数据进行了消费。当然了，对由于执行该方法而进入阻塞的线程执行中断
操作也可以使当前线程退出阻塞。该方法的返回值boolean为true时表示写入数据成功，
为false时表示写入数据失败。

2. 非阻塞式写方法
当队列已满时写入数据，如果不想使得当前线程进入阻塞，那么就可以使用非阻塞式的写操作方法。
▪ boolean add(E e)：向队列尾部写入新的数据，当队列已满时不会进入阻塞，但是该方法会抛出队列已满的异常。
▪ boolean offer(E e)：向队列尾部写入新的数据，当队列已满时不会进入阻塞，并且会立即返回false。

3. 阻塞式读方法
ArrayBlockingQueue中提供了两个阻塞式读方法，分别如下。
▪ E take()：从队列头部获取数据，并且该数据会从队列头部移除，当队列为空时执行take方法的线程将进入阻塞，
直到有其他线程写入新的数据，或者当前线程被执行了中断操作。
▪ E poll(long timeout, TimeUnit unit)：从队列头部获取数据并且该数据会从队列头部移除，
如果队列中没有任何元素时则执行该方法，当前线程会阻塞指定的时间，直到在此期间有新的数据写入，
或者阻塞的当前线程被其他线程中断，当线程由于超时退出阻塞时，返回值为null。

4. 非阻塞式读方法
当队列为空时读取数据，如果不想使得当前线程进入阻塞，那么就可以使用非阻塞式的读操作方法。
▪ E poll()：从队列头部获取数据并且该数据会从队列头部移除，当队列为空时，该方法不会使得当前线程进入阻塞，
而是返回null值。
▪ E peek()：peek的操作类似于debug操作（仅仅debug队列头部元素），它直接从队列头部获取一个数据，
但是并不能从队列头部移除数据，当队列为空时，该方法不会使得当前线程进入阻塞，而是返回null值。

</pre>

### PriorityBlockingQueue
- NOTE
<pre>PriorityBlockingQueue优先级阻塞队列是一个“无边界”阻塞队列，该队列会根据某种规则
（Comparator）对插入队列尾部的元素进行排序，因此该队列将不会遵循FIFO
（first-in-first-out）的约束。虽然PriorityBlockingQueue同ArrayBlockingQueue都实现自同样的
接口，拥有同样的方法，但是大多数方法的实现确实具有很大的差别，PriorityBlockingQueue也是
线程安全的类，适用于高并发多线程的情况下。

1. 排序且无边界的队列
只要应用程序的内存足够使用，理论上，PriorityBlockingQueue存放数据的数量是“无边界”的，
在PriorityBlockingQueue内部维护了一个Object的数组，随着数据量的不断增多，
该数组也会进行动态地扩容。在构造PriorityBlockingQueue时虽然提供了一个整数类型的参数，
但是该参数所代表的含义与ArrayBlockingQueue完全不同，前者是构造PriorityBlockingQueue的
初始容量，后者指定的整数类型参数则是ArrayBlockingQueue的最大容量。
根据我们的理解，既然是优先级排序队列，为何在构造PriorityBlockingQueue时并未指定任何数据
排序相关的接口呢？事实上，如果没有显示地指定Comparator，那么它将只支持实现了
Comparable接口的数据类型。比如，Integer类型是Comparable的子类，
因此我们并不需要指定Comparator，默认情况下，优先级最小的数据元素将被放在队列头部，
优先级最大的数据元素将被放在队列尾部。
如果在创建PriorityBlockingQueue队列的时候既没有指定Comparator，同时数据元素也不是
Comparable接口的子类，那么这种情况下，会出现类型转换的运行时异常。

2. 不存在阻塞写方法
由于PriorityBlockingQueue是“无边界”的队列，因此将不存在对队列上限临界值的控制，在PriorityBlockingQueue中，
添加数据元素的所有方法都等价于offer方法，从队列的尾部添加数据，但是该数据会根据排序规则
对数据进行排序。

3. 优先级队列读方法
优先级队列添加元素的方法不存在阻塞（由于是“无边界”的），但是针对优先级队列元素的读方法则与ArrayBlockingQueue类似。

</pre>

### LinkedBlockingQueue
- NOTE
<pre>LinkedBlockingQueue是“可选边界”基于链表实现的FIFO队列。LinkedBlockingQueue队列的边界
可选性是通过构造函数来决定的，当我们在创建LinkedBlockingQueue对象时，使用的是默认的构造
函数，那么该队列的最大容量将为Integer的最大值（所谓的“无边界”），当然开发者可以通过指定
队列最大容量（有边界）的方式创建队列。

LinkedBlockingQueue与ArrayBlockingQueue极其相似。</pre>

### DelayQueue
- NOTE
<pre>DelayQueue也是一个实现了BlockingQueue接口的“无边界”阻塞队列，但是该队列却是非常有意思
和特殊的一个队列（存入DelayQueue中的数据元素会被延迟单位时间后才能消费），
在DelayQueue中，元素也会根据优先级进行排序，这种排序可以是基于数据元素过期时间而进行的
（比如，你可以将最快过期的数据元素排到队列头部，最晚过期的数据元素排到队尾）。
对于存入DelayQueue中的元素是有一定要求的：元素类型必须是Delayed接口的子类，
存入DelayQueue中的元素需要重写getDelay(TimeUnit unit)方法用于计算该元素距离过期的
剩余时间，如果在消费DelayQueue时发现并没有任何一个元素到达过期时间，那么对该队列的读取
操作会立即返回null值，或者使得消费线程进入阻塞。

读取DelayQueue中的数据
DelayQueue队列区别于之前的队列，其中之一就是存入该队列的元素必须是Delayed的
子类，除此之外队列中的数据元素会被延迟（Delay）消费，这也正是延迟队列名称的由来。
与PriorityBlockingQueue一样，DelayQueue中有关增加元素的所有方法都等价于offer(E e)，
并不存在针对队列临界值上限的控制，因此也不存在阻塞写的情况（多线程争抢导致的线程阻塞另当别论）
但是对该队列中数据元素的消费（延迟消费）则有别于其他阻塞队列。
▪ remainingCapacity()方法始终返回Integer.MAX_VALUE
▪ peek()：非阻塞读方法，立即返回但并不移除DelayQueue的头部元素，当队列为空时返回null。队列不为空
时，peek方法不会出现延迟，而是立即返回队列头部的元素，但不移除。
▪ poll():非阻塞读方法，当队列为空或者队列头部元素还未到达过期时间时返回值为null，否则将会从队列头部立即将元素移除并返回。
▪ poll(long timeout, TimeUnit unit)：最大阻塞单位时间，当达到阻塞时间后，此刻为空或者队列
头部元素还未达到过期时间时返回值为null，否则将会立即从队列头部将元素移除并返回。
▪ take()：阻塞式的读取方法，该方法会一直阻塞直到队列中有元素，并且队列中的头部元素已达到
过期时间，然后将其从队列中移除并返回。
</pre>

### ArrayBlockingQueue和LinkedBlockingQueue比较
- NOTE
<pre>https://www.cnblogs.com/lianliang/p/5765349.html

相同：
LinkedBlockingQueue和ArrayBlockingQueue都是可阻塞的队列
内部都是使用ReentrantLock和Condition来保证生产和消费的同步；
当队列为空，消费者线程被阻塞；当队列装满，生产者线程被阻塞；
使用Condition的方法来同步和通信：await()和signal()

不同：
1、锁机制不同
　　LinkedBlockingQueue中的锁是分离的，生产者的锁PutLock，消费者的锁takeLock，
而ArrayBlockingQueue生产者和消费者使用的是同一把锁；
2、底层实现机制也不同
　　LinkedBlockingQueue内部维护的是一个链表结构。
在生产和消费的时候，需要创建Node对象进行插入或移除，大批量数据的系统中，
其对于GC的压力会比较大。
而ArrayBlockingQueue内部维护了一个数组，在生产和消费的时候，
是直接将枚举对象插入或移除的，不会产生或销毁任何额外的对象实例。

3、构造时候的区别
　　LinkedBlockingQueue有默认的容量大小为：Integer.MAX_VALUE，
当然也可以传入指定的容量大小，ArrayBlockingQueue在初始化的时候，必须传入一个容量大小的值

4、执行clear()方法
　　LinkedBlockingQueue执行clear方法时，会加上两把锁

 5、统计元素的个数
　　LinkedBlockingQueue中使用了一个AtomicInteger对象来统计元素的个数，ArrayBlockingQueue则使用int类型来统计元素。</pre>

### SynchronousQueue
- NOTE
<pre>SynchronousQueue也是实现自BlockingQueue的一个阻塞队列，每一次对其的写入操作必须等待
（阻塞）其他线程进行对应的移除操作，SynchronousQueue的内部并不会涉及容量、获取size，
就连peek方法的返回值永远都将会是null，除此之外还有更多的方法在SynchronousQueue中也
都未提供对应的支持（列举如下），因此在使用的过程中需要引起注意，否则会使得程序的运行出现
不符合预期的错误。
▪ clear()：清空队列的方法在SynchronousQueue中不起任何作用。
▪ contains(Object o)：永远返回false。
▪ containsAll(Collection&lt;?&gt; c)：等价于c是否为空的判断。
▪ isEmpty()：永远返回true。▪ iterator()：返回一个空的迭代器。
▪ peek()：永远返回null。▪ remainingCapacity()：始终返回0。
▪ remove(Object o)：不做任何删除，并且始终返回false。
▪ removeAll(Collection&lt;?&gt; c)：不做任何删除，始终返回false。
▪ retainAll(Collection&lt;?&gt; c)：始终返回false。
▪ size()：返回值始终为0。
▪ spliterator()：返回一个空的Spliterator。
▪ toArray()及toArray(T[] a)方法同样也不支持。

简单来说，我们可以借助于SynchronousQueue在两个线程间进行线程安全的数据交换，
这一点比较类似于Exchanger工具类。
尽管SynchronousQueue是一个队列，但是它的主要作用在于在两个线程之间进行数据交换，
区别于Exchanger的主要地方在于（站在使用的角度）SynchronousQueue所涉及的一对线程一个
更加专注于数据的生产，另一个更加专注于数据的消费（各司其职），而Exchanger则更加强调一
对线程数据的交换。Exchanger可以看作一个双向的SynchronousQueue。
</pre>

### LinkedBlockingDeque
- NOTE
<pre>LinkedBlockingDeque是一个基于链表实现的双向（Double EndedQueue，Deque）阻塞队列，
双向队列支持在队尾写入数据，读取、移除数据；在队头写入数据，读取、移除数据。
LinkedBlockingDeque实现自BlockingDeque（BlockingDeque又是BlockingQueue的子接口），
并且支持可选“边界”，与LinkedBlockingQueue一样，对边界的指定在构造LinkedBlockingDeque时就已经确定了。</pre>

### LinkedTransferQueue
- NOTE
<pre>TransferQueue是一个继承了BlockingQueue的接口，并且增加了若干新的方法。
LinkedTransferQueue是TransferQueue接口的实现类，其定义为一个无界的队列，具有FIFO的特性。
1. transfer方法
当某个线程执行了transfer方法后将会进入阻塞，直到有其他线程对transfer的数据元素进行了poll
或者take，否则当前线程会将该数据元素插入队列尾部，并且等待其他线程对其进行消费。
这段文字描述包含了一些非常苛刻的要求，首先，LinkedTransferQueue是一个队列，
是可以存放无限（Integer.MAX_VALUE）数据元素的队列，因此允许同时有多个线程将数据元素
插入队列尾部；其次当线程A通过transfer方法将元素E插入队列尾部时，即使此时此刻有其他线程
也对该队列进行着消费操作，如果元素E未被消费，那么线程A同样也会进入阻塞直到元素E被其他
线程消费。
transfer方法的主要特性，非常类似于SynchronousQueue的put方法，
但是不同于SynchronousQueue的地方在于LinkedTransferQueue存在容量，
允许无限多个数据元素的插入，而前者则不支持。

2. tryTransfer方法与transfer方法不同的是，tryTransfer方法并不会使得执行线程进入阻塞，
如果当前并没有线程等待对元素E的消费（poll或者take），那么执行tryTransfer方法会立即返回失败，
并且元素E也不会插入队列的尾部（transfer不成功），否则返回成功。
tryTransfer还有一个重载方法，支持最大超时时间的设定，在设定的最大超时时间内，
如果没有其他线程对transfer的数据元素进行消费，那么元素E将不会被插入队列尾部，并且退出阻塞，
如果在单位时间内有其他线程消费transfer的元素数据，则元素成功插入队尾并退出阻塞。

3. 其他monitor方法
在TransferQueue中还提供了两个与monitor相关的方法，主要用于获取当前是否有消费者线程在等待消费TransferQueue中的数据。</pre>

## ConcurrentQueue（并发队列）
> leftSide=`true`

- NOTE
<pre>虽然每一种阻塞队列都有各自的特性和实现方式，但是它们解决的问题主要是，当队列达到某临界值时，
与之对应的线程被挂起以等待其他线程的唤醒通知，对于这样的场景我们在日常的程序开发中会经常
使用到，其有一个非常专业和学术的叫法，即生产者消费者模型（模式）。

在绝大多数的BlockingQueue中，为了保护共享数据的一致性，需要对共享数据的操作进行加锁处理
（显式锁或者synchronized关键字），为了使得操作线程挂起和被唤醒，我们需要借助于对象监视器
的wait/notify/notifyAll或者与显式锁关联的Condition。

那么，在Java中有没有一种队列的实现方式可以不用关心临界值的判断，操作该队列的线程也不会
被挂起并且等待被其他线程唤醒，我们只是单纯地向该队列中插入或者获取数据，并且该队列是线程
安全的，是可以应用于高并发多线程的场景中呢？在JDK1.5版本以前要实现这些要求我们
大致有两种方式，具体如下。
1）通过synchronized关键字对非线程安全的队列或者链表的操作方法进行同步。
2）使用Collections类的同步方法。
这种方式虽然可以确保Collection在多线程环境下的线程安全性，但是synchronized关键字相对于
显式锁Lock甚至无锁的实现方式来说效率低下，因此自JDK1.5版本后，Java的开发者们实现了无锁的
且线程安全的并发队列实现方案，开发者可以直接借助于它们开发出高性能的应用程序。
▪ ConcurrentLinkedQueue：无锁的、线程安全的、性能高效的、基于链表结构实现的FIFO单向队列（在JDK1.5版本中被引入）。
▪ ConcurrentLinkedDeque：无锁的、线程安全的、性能高效的、基于链表结构实现的双向队列（在JDK1.7版本中被引入）。
</pre>

### 并发队列在使用中需要注意的问题
- NOTE
<pre>虽然并发队列在高并发多线程的环境中有着优异的性能表现，但是如果对其使用不当不仅对性能没有
任何提升反倒会降低整个系统的运行效率。
1. 在并发队列中使用size方法不是个好主意
我们知道每一个Collection（队列Queue也是Collection的子接口）都提供了size()方法用于获取
Collection中的元素个数，但是在并发队列中执行该方法却不是一个明智的操作，为什么呢？
▪ 首先，并发队列是基于链表的结构实现的，并且在其内部并未提供类似于计数器的变量
（当元素插入队列计数器时增一，当元素从队列头部被移除时计数器减一），
因此想要获得当前队列的元素个数，需要遍历整个队列才能计算得出（效率低下）。
▪ 其次并发队列采用无锁（Lock-Free）的算法实现，因此在某个线程中执行size()方法获取元素数量
的同时，其他线程也可以对该队列进行读写操作，所以size()返回的数值不会是一个精确值，
而是一个近似值、一个估计值。

2. ConcurrentLinkedQueue的内存泄漏问题
另外，ConcurrentLinkedQueue在执行remove方法
删除元素时还会出现性能越来越低，甚至内存泄漏的问题。这个问题最早是由Jetty的开发者发现的，
因为Jetty内部的线程池采用的就是ConcurrentLinkedQueue作为任务的队列，随后在很多开源项目
中都发现了内存泄漏的问题，比如Apache Cassandra。
▪ JDK BUG地址：https:// bugs.java.com/bugdatabase/view_bug.do?bug_id=8137185
▪ Jetty BUG地址：https:// bugs.eclipse.org/bugs/show_bug.cgi?id=477817
▪ Cassandra BUG地址：https://issues.apache.org/jira/browse/CASSANDRA-9549
值得庆幸的是，在Jetty中该问题被发现后得到了解决，开发者们采用ConcurrentHashSet替代了
ConcurrentLinkedQueue的解决方案，不过很遗憾的是，在JDK的7、8、9版本中该问题依然存在
（我用8测试的时候并没有发现有这个问题）。</pre>

## ConcurrentMap（并发映射）
> leftSide=`true`


### ConcurrentHashMap
- NOTE
<pre>ConcurrentHashMap是专门为多线程高并发场景而设计的Map，它的get()操作基本上是lock-free的，
同时put()方法又将锁的粒度控制在很小的范围之内，因此它非常适合于多线程的应用程序之中。

1. JDK1.8版本以前的ConcurrentHashMap内部结构
在JDK1.6、1.7版本中，ConcurrentHashMap采用的是分段锁的机制（可以在确保线程安全的同时
最小化锁的粒度）实现并发的更新操作，在ConcurrentHashMap中包含两个核心的静态内部类
Segment和HashEntry，前者是一个实现自ReentrantLock的显式锁，每一个Segment锁对象均
可用于同步每个散列映射表的若干个桶（HashBucket），后者主要用于存储映射表的键值对。
与此同时，若干个HashEntry通过链表结构形成了HashBucket，而最终的ConcurrentHashMap
则是由若干个（默认是16个）Segment对象数组构成的。
Segment可用于实现减小锁的粒度，ConcurrentHashMap被分割成若干个Segment，
在put的时候只需要锁住一个Segment即可，而get时候则干脆不加锁，而是使用volatile属性以保证
被其他线程同时修改后的可见性。

2. JDK1.8版本ConcurrentHashMap的内部结构
在JDK 1.8版本中几乎重构了ConcurrentHashMap的内部实现，摒弃了segment的实现方式，直接用table数组存储键值对，
在JDK1.6中，每个bucket中键值对的组织方式都是单向链表，查找复杂度是O(n)，JDK1.8中当链表长度超过8时，链表转换为红黑树，
查询复杂度可以降低到O(log n)，改进了性能。利用CAS+Synchronized可以保证并发更新的安全性，底层则采用数组+链表+红黑树
（提高检索效率）的存储结构。</pre>

### ConcurrentSkipListMap
- NOTE
<pre>ConcurrentSkipListMap提供了一种线程安全的并发访问的排序映射表。内部是SkipList（跳表）
结构实现，在理论上，其能够在O(log(n))时间内完成查找、插入、删除操作。
调用ConcurrentSkipListMap的size时，由于多个线程可以同时对映射表进行操作，
所以映射表需要遍历整个链表才能返回元素的个数，这个操作是个O(n)的操作。
在读取性能上，虽然ConcurrentSkipListMap不能与ConcurrentHashMap相提并论，
但是ConcurrentSkipListMap存在着如下两大天生的优越性是ConcurrentSkipListMap所不具备的。
第一，由于基于跳表的数据结构，因此ConcurrentSkipListMap的key是有序的。
第二，ConcurrentSkipListMap支持更高的并发，ConcurrentSkipListMap的存取时间复杂度是O（log（n）），
与线程数几乎无关，也就是说，在数据量一定的情况下，并发的线程越多，ConcurrentSkipListMap越能体现出它的优势。
</pre>

## 写时拷贝算法（Copy On Write）
- NOTE
<pre>CopyOnWrite容器，简称COW，该容器的基本实现思路是在程序运行的初期，所有的线程都共享
一个数据集合的引用。所有线程对该容器的读取操作将不会对数据集合产生加锁的动作，
从而使得高并发高吞吐量的读取操作变得高效，但是当有线程对该容器中的数据集合进行删除或增加
等写操作时才会对整个数据集合进行加锁操作，然后将容器中的数据集合复制一份，并且基于最新的
复制进行删除或增加等写操作，当写操作执行结束以后，将最新复制的数据集合引用指向原有的数据
集合，进而达到读写分离最终一致性的目的。
这样做的好处是多线程对CopyOnWrite容器进行并发的读是不需要加锁的，因为当前容器中的数据
集合是不会被添加任何元素的（关于这一点，CopyOnWrite算法可以保证），所以CopyOnWrite
容器是一种读写分离的思想，读和写不同的容器，因此不会存在读写冲突，而写写之间的冲突则
是由全局的显式锁Lock来进行防护的，因此CopyOnWrite常常被应用于读操作远远高于写操作的
应用场景中。

Java中提供了两种CopyOnWrite算法的实现类，具体如下：
▪ CopyOnWriteArrayList：在JDK1.5版本被引入，用于高并发的ArrayList解决方案，
在某种程度上可以替代Collections.synchronizedList。
▪ CopyOnWriteArraySet：也是自JDK1.5版本被引入，提供了高并发的Set的解决方案，
其实在底层，CopyOnWriteArraySet完全是基于CopyOnWriteArrayList实现的。

从CopyOnWrite源码中我们发现，在对CopyOnWrite容器进行读操作时不会进行加锁同步操作，
因此允许同一时间多个线程同时操作。
CopyOnWrite容器在进行写操作时，首先会加锁整个容器，然后拷贝一份新的副本，再针对副本进行操作，
最后将副本赋值于全局的数据集合引用，由于锁的加持，写操作在同一时刻只允许一个线程进行写操作。

虽然COW算法为解决高并发读操作提供了一种新的思路（读写分离），但是其仍然存在一些天生的
缺陷，具体如下：
▪ 数组复制带来的内存开销：因为CopyOnWrite的写时复制机制，所以在进行写操作的时候，
内存里会同时驻扎两个对象的内存，旧的数据集合和新拷贝的数据集合，当然旧的数据集合在拷贝
结束以后会满足被回收的条件，但是在某个时间段内，内存还是会有将近一半的浪费。
▪ CopyOnWrite并不能保证实时的数据一致性：CopyOnWrite容器只能保证数据的最终一致性，
并不能保证数据的实时一致性。举个例子，假设A线程修改了数据复制并且增加了一个新的元素
但并未将数据集合的引用指向最新复制，与此同时，B线程是从旧的数据集合中读取元素，
因此A写入的数据并不能实时地被B线程读取。

既然CopyOnWrite并不是一个很完美的高并发线程安全解决方案，那么它的应用场景又该是怎样的呢？
其实我们在本节中已经提到过了，对于读操作远大于写操作，并且不要求实时数据一致性的情况，
CopyOnWrite容器将是一个很合理的选择，比如在规则引擎中对新规则的引入、
在告警规则中对新规则的引入、在黑白名单中对新数据的引入，并不一定需要严格保证数据的实时
一致性，我们只需要确保在单位时间后的最终一致性即可，在这种情况下，我们就可以采用COW
算法提高数据的读取速度及性能。</pre>

### CopyOnWriteArrayList真的完全线程安全吗
- NOTE
<pre>https://www.jianshu.com/p/fc0ee3aaf2df
数组越界
如果有第一个线程进行删除元素操作，读线程去读取容器中最后一个元素，读之前的时候容器大小为i，
当去读的时候删除线程突然删除了一个元素，这个时候容器大小变为了i-1，读线程仍然去读取第i个
元素，这时候就会发生数组越界。
CopyOnWriteArrayList并不是完全意义上的线程安全，如果涉及到remove操作，一定要谨慎处理。</pre>

## 高并发无锁（Lock Free）数据结构的实现
> leftSide=`true`

- NOTE
<pre>参考com.chenjj.concurrent.containers.lockFree.LockFreeLinkedList</pre>

### Lock Free算法
- NOTE
<pre>如果您对Lock Free算法比较感兴趣，那么建议参考下面几篇文章和论文。
▪ https:// www.cs.cmu.edu/~410-s05/lectures/L31_LockFree.pdf
▪ http:// concurrencykit.org/presentations/lockfree_introduction/#/
▪ http:// www.rossbencina.com/code/lockfree</pre>
